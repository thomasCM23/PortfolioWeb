<h4>Neural Machine Translation</h4>
<a href="https://github.com/tensorflow/nmt">
    <h6>Following This Tutorial</h6>
</a>

<div>
    <p>
        This tutorial gives readers a full understanding of seq2seq models and shows how to build a competitive seq2seq
        model from scratch. We focus on the task of Neural Machine Translation (NMT) which was the very first testbed
        for seq2seq models with wild success. The included code is lightweight, high-quality, production-ready, and
        incorporated with the latest research ideas.
    </p>
    <br>
    <p>
        Following the tutorial I created a neural machine translation for english to french, using encoder-decoder with standard attention.
        The encoder and decoder both had 4 layers of 1024 long short term memory units(LSTM), standard attention uses top layer of network
        to compute attention. 
        The data used is from <a href="http://www.statmt.org/wmt14/translation-task.html">Statistical Machine Translation</a>. My goal was
        to use the opensourced nmt code and create a api which would translate incoming sentences into the desired language, gaining a
        better understanding of RNNs, LSTM units, Attention mechanisms and Tensorflow. I trained the network for 2 days, by the 
        end it achieved a BLEU score of near 30. Note having been trained on text that is often news and political it fairs better at translating
        similar text, common vernacular will not translate well.
    </p>
    <br>
    <p>
        With the help of the following papers, I was able to gain a better understanding of the task at hand.
        <ul>
            <li>Sequence to Sequence Learning with Neural Networks(Ilya Sutskever, Oriol Vinyals, Quoc V. Le)</li>
            <li>Recurrent Neural Network Regularization(Wojciech Zaremba, Ilya Sutskever, Oriol Vinyals)</li>
            <li>Learning Phrase Representation using RNN Encoder-Decoder for Statistical Machine Translation(Kyunghyun Cho, Bart van MerriÃ«nboer, Et al.)</li>
            <li>Effective Approaches to Attention-based Neural Machine Translation(Minh-Thang Luong, Hieu Pham, Christopher D. Manning)</li>
        </ul>
    </p>
    <br>
</div>
<div class="mdc-card demo-size" style="padding:2%">
    <div class="demo-card__primary">
        <h2 class="demo-card__title" style="color: #000">Example</h2>
    </div>
    <div class="demo-card__secondary">
        <div class="grid-container fluid">
            <textarea type="" [(ngModel)]="form.original_text" rows="4"></textarea>
            <br>
            <material-button class="card-button" (click)="translate()">Translate!</material-button>
            <hr>
            <p style="color: #000;white-space: pre-line">
                {{form.transText}}
            </p>
        </div>
    </div>
</div>